{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI-generated by ChatGPT\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üìä Text Analysis & Spam Detection Model Training\\n\",\n",
    "    \"### Final Project ‚Äî Spam/Fraud Detection\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook documents:\\n\",\n",
    "    \"- Loading the spam dataset\\n\",\n",
    "    \"- Text cleaning\\n\",\n",
    "    \"- Exploratory data analysis (EDA)\\n\",\n",
    "    \"- Feature extraction (TF-IDF)\\n\",\n",
    "    \"- Training an MLP classifier\\n\",\n",
    "    \"- Evaluating performance\\n\",\n",
    "    \"- Saving the trained model + vectorizer\\n\",\n",
    "    \"\\n\",\n",
    "    \"**This notebook supports the code located in the `/src` and `/models` directories.**\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üì• 1. Load Dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from datasets import load_dataset\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataset = load_dataset(\\\"mshenoda/spam-messages\\\")\\n\",\n",
    "    \"df = dataset['train'].to_pandas()\\n\",\n",
    "    \"\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìä 2. Clean Text\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import re\\n\",\n",
    "    \"import string\\n\",\n",
    "    \"\\n\",\n",
    "    \"def clean_text(text):\\n\",\n",
    "    \"    text = text.lower()\\n\",\n",
    "    \"    text = re.sub(r\\\"http\\\\S+\\\", \\\"\\\", text)\\n\",\n",
    "    \"    text = text.translate(str.maketrans(\\\"\\\", \\\"\\\", string.punctuation))\\n\",\n",
    "    \"    text = re.sub(r\\\"\\\\s+\\\", \\\" \\\", text).strip()\\n\",\n",
    "    \"    return text\\n\",\n",
    "    \"\\n\",\n",
    "    \"df['clean_text'] = df['text'].apply(clean_text)\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîé 3. Simple EDA (Exploratory Data Analysis)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df['label'].value_counts()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df['char_count'] = df['clean_text'].apply(len)\\n\",\n",
    "    \"df['char_count'].describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"df['token_count'] = df['clean_text'].apply(lambda x: len(x.split()))\\n\",\n",
    "    \"df['token_count'].describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîß 4. TF-IDF Vectorizer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n",
    "    \"\\n\",\n",
    "    \"vectorizer = TfidfVectorizer(max_features=5000)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X = vectorizer.fit_transform(df['clean_text']).toarray()\\n\",\n",
    "    \"y = df['label'].apply(lambda x: 1 if x == 'spam' else 0).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"X.shape, y.shape\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## ‚úÇÔ∏è 5. Train/Test Split\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 7,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, test_size=0.2, random_state=42, stratify=y\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train.shape, X_test.shape\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üß† 6. MLP Classifier (PyTorch)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 8,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import torch.optim as optim\\n\",\n",
    "    \"\\n\",\n",
    "    \"class MLPClassifier(nn.Module):\\n\",\n",
    "    \"    def __init__(self, input_dim):\\n\",\n",
    "    \"        super().__init__()\\n\",\n",
    "    \"        self.model = nn.Sequential(\\n\",\n",
    "    \"            nn.Linear(input_dim, 256),\\n\",\n",
    "    \"            nn.ReLU(),\\n\",\n",
    "    \"            nn.Dropout(0.3),\\n\",\n",
    "    \"            nn.Linear(256, 128),\\n\",  \n",
    "    \"            nn.ReLU(),\\n\",\n",
    "    \"            nn.Linear(128, 1)\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def forward(self, x):\\n\",\n",
    "    \"        return self.model(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"device = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\",\n",
    "    \"model = MLPClassifier(5000).to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"criterion = nn.BCEWithLogitsLoss()\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=1e-3)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üî• 7. Training Loop\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 9,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\\n\",\n",
    "    \"y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for epoch in range(10):\\n\",\n",
    "    \"    optimizer.zero_grad()\\n\",\n",
    "    \"    logits = model(X_train_tensor)\\n\",\n",
    "    \"    loss = criterion(logits, y_train_tensor)\\n\",\n",
    "    \"    loss.backward()\\n\",\n",
    "    \"    optimizer.step()\\n\",\n",
    "    \"    print(f\\\"Epoch {epoch+1}/10 - Loss: {loss.item():.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üß™ 8. Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 10,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\\n\",\n",
    "    \"with torch.no_grad():\\n\",\n",
    "    \"    preds = torch.sigmoid(model(X_test_tensor)).cpu().numpy().flatten()\\n\",\n",
    "    \"\\n\",\n",
    "    \"pred_labels = (preds >= 0.5).astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"acc = accuracy_score(y_test, pred_labels)\\n\",\n",
    "    \"prec = precision_score(y_test, pred_labels)\\n\",\n",
    "    \"rec = recall_score(y_test, pred_labels)\\n\",\n",
    "    \"f1 = f1_score(y_test, pred_labels)\\n\",\n",
    "    \"\\n\",\n",
    "    \"acc, prec, rec, f1\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üíæ 9. Save Model + Vectorizer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 11,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pickle\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"MODEL_DIR = \\\"../models/text/\\\"\\n\",\n",
    "    \"os.makedirs(MODEL_DIR, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"torch.save(model.state_dict(), MODEL_DIR + \\\"text_model_adam.pt\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"with open(MODEL_DIR + \\\"tfidf_vectorizer.pkl\\\", \\\"wb\\\") as f:\\n\",\n",
    "    \"    pickle.dump(vectorizer, f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved model and vectorizer ‚úîÔ∏è\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
